{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import timm\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import model_selection, metrics\n",
    "\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos los datos de Kaggle y los cargamos en un DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734dca39",
   "metadata": {},
   "source": [
    "Para este proyecto se hará uso del TPU proporcionado por Kaggle, para lo cual implementaremos primero paralelización del TPU. Esto nos permitirá acelerar el entrenamiento de modelos de deep learning utilizando la librería Torch XLA, que facilita la integración de PyTorch con dispositivos TPU. La paralelización se logra distribuyendo los datos y el proceso de entrenamiento entre los diferentes núcleos del TPU, optimizando así el uso de recursos y reduciendo significativamente el tiempo de entrenamiento. Además, se emplearán técnicas como el uso de DataLoader y ParallelLoader para manejar eficientemente los datos durante el entrenamiento distribuido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d2063",
   "metadata": {},
   "source": [
    "os.environ[\"XLA_USE_BF16\"] = \"1\"\n",
    "os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para la reproducibilidad de los resultados hacemos uso de una semilla fija\n",
    "# Esto asegura que los resultados sean consistentes en diferentes ejecuciones\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
